{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ANACONDA\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_ROTATE = -1\n",
    "NUMBER_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGE CODES AND CORRECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_corrections(label_code):\n",
    "    if label_code == 0:\n",
    "        return cv2.ROTATE_90_CLOCKWISE\n",
    "    elif label_code == 1:\n",
    "        return cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "    elif label_code == 2:\n",
    "        return NOT_ROTATE\n",
    "    elif label_code == 3:\n",
    "        return cv2.ROTATE_180\n",
    "\n",
    "def correct_image(image, rot_correction):\n",
    "    if rot_correction == NOT_ROTATE:\n",
    "        return image\n",
    "    else:\n",
    "        return cv2.rotate(image, rot_correction)    \n",
    "\n",
    "def code_tolabels(label_code):    \n",
    "    if label_code == 0:\n",
    "        return 'rotated_left'\n",
    "    elif label_code == 1:\n",
    "        return 'rotated_right'\n",
    "    elif label_code == 2:\n",
    "        return 'upright'\n",
    "    elif label_code == 3:\n",
    "        return 'upside_down'\n",
    "\n",
    "def labels_toonehot(label):\n",
    "    if label == 'rotated_left':\n",
    "        return 0\n",
    "    elif label == 'rotated_right':\n",
    "        return 1\n",
    "    elif label == 'upright':\n",
    "        return 2\n",
    "    elif label == 'upside_down':\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_list, to_preprocess = True):\n",
    "    data = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(DATA_FOLDER, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        if to_preprocess:\n",
    "            image = preprocess(image)\n",
    "        data.append(image)\n",
    "\n",
    "    data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def preprocess(image):\n",
    "    image = cv2.resize(image, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255\n",
    "    return image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(file_list, model):\n",
    "    data_xi = load_data(file_list)\n",
    "    ypred_i = model.predict(data_xi)\n",
    "    ypred_i = np.argmax(ypred_i, axis=1)\n",
    "    return ypred_i\n",
    "\n",
    "def write_orientated_images(file_list, model, folder = ''):\n",
    "    file_dir = os.path.join(os.getcwd(), folder)    \n",
    "    \n",
    "    original_images = load_data(file_list, False)\n",
    "    ypred_i = prediction(file_list, model)\n",
    "    corrections = [rot_corrections(x) for x in ypred_i]\n",
    "    file_names = [x.split('.')[0] for x in file_list]\n",
    "    corrected_images = []\n",
    "    \n",
    "    for file_name, image, correction in zip(file_list, original_images, corrections):\n",
    "        image_corr = correct_image(image, correction)\n",
    "        corrected_images.append(image_corr)\n",
    "        file_name = os.path.join(file_dir, file_name)    \n",
    "        #cv2.imwrite(file_name + '.png', image_corr)\n",
    "    \n",
    "    results = [\n",
    "        [code_tolabels(x) for x in ypred_i],\n",
    "        np.array(corrected_images)]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'rotvision_trained_model.h5'\n",
    "\n",
    "# load json and create model\n",
    "model_json_path = os.path.join(save_dir, model_name.split('.')[0] + '.json')\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "json_file = open(model_json_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_path)\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)  # 2.2.0 to 2.3.1  --> lr changed to learning_rate\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])    \n",
    "\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "for root, dirs, files in os.walk('test'):\n",
    "    test_files += files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = test_files\n",
    "DATA_FOLDER = 'test'\n",
    "\n",
    "batch_size=32\n",
    "number_batches = int(len(all_files) / batch_size) + 1\n",
    "pred_labels = []\n",
    "corrected_images = []\n",
    "for i in range(number_batches):\n",
    "    start = i* batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "\n",
    "    file_list = all_files[start:end]\n",
    "    if len(file_list) == 0:\n",
    "        break\n",
    "    results = write_orientated_images(file_list, loaded_model, 'ziptest')\n",
    "    pred_labels += results[0]\n",
    "    corrected_images.append(results[1])\n",
    "\n",
    "corrected_images = np.array(corrected_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = {}\n",
    "test_pred['fn'] = all_files\n",
    "test_pred['label'] = pred_labels\n",
    "pd.DataFrame(test_pred).to_csv('test.preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_array.npy', corrected_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
